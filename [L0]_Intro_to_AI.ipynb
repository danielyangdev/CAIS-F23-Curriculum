{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielyangdev/CAIS-F23-Curriculum/blob/main/%5BL0%5D_Intro_to_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lesson 0 Notebook: Numpy, Pandas, & Pytorch Basics**\n",
        "\n",
        "##Welcome to your first notebook in CAIS++!\n",
        "\n",
        "**Noteboook Objective**: Notebooks are meant to help you *apply* knowledge you've learned in the lesson, and should generally take about 45 minutes - 1 hour. This particular notebook will allow you to learn and experiment with some popular Python libraries used for data manipulation and visualization. We will also introduce tensors, the basic data structure in Pytorch, which is the machine learning framework we will be using for a majority of our curriculum!\n",
        "\n",
        "**Useful Links**:\n",
        "\n",
        "\n",
        "*   [Python Cheatsheet](https://www.pythoncheatsheet.org/): recaps Python basics, flow control, funtions, data structures, etc.\n",
        "*   [Tensor Operation Documentation](https://pytorch.org/docs/stable/torch.html): 100+ tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing,\n",
        "indexing, slicing), sampling and more\n",
        "\n",
        "**Important!**: Before you run any cells, click `Runtime --> Change Runtime Type --> T4 GPU (under the Hardware Accelerator Dropdown menu)`. We will talk more about the benefits of this in a later part of the notebook!\n",
        "\n"
      ],
      "metadata": {
        "id": "ig-fDxQ-g6nn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "The following three cells are necessary for setting up our development environment.\n",
        "- `import drive` allows us to utilize the files that exist within our Google Drive.\n",
        "- `%cd` navigates towards a folder that contains necessary files and training data.\n",
        "- `!ls` displays the files that exist within the aforementioned folder (a.k.a. current working directory)."
      ],
      "metadata": {
        "id": "5Oc-fls0ivRm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wuMBeSZcBF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "261bce99-1163-46c7-f0be-3c1331f1dd4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cd stands for \"change directory\" -- move to the path described below\n",
        "%cd /content/drive/MyDrive/Other/CAIS++/F23_Curriculum/L0/Notebooks"
      ],
      "metadata": {
        "id": "d-akaqdoi7U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6619d32a-7c3d-4f0b-9078-ed7b8cbb9fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Other/CAIS++/F23_Curriculum/L0/Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ls stands for \"list\" -- list files in the working directory\n",
        "!ls"
      ],
      "metadata": {
        "id": "uVVb7kh6mPgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "## **Pandas**\n",
        "[*pandas*](http://pandas.pydata.org/) is a column-oriented data analysis API. It's a great tool for handling and analyzing input data, and many ML frameworks support *pandas* data structures as inputs.\n",
        "\n",
        "The following line imports the *pandas* API and prints the API version:"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "s_JOISVgmn9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import pandas as pd\n",
        "pd.__version__"
      ],
      "metadata": {
        "id": "cXUJzW1ApY9p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fef21757-7a4d-4001-9e70-17491b19f911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.5.3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary data structures in pandas are implemented as two classes:\n",
        "\n",
        "*   **DataFrame**: a relational data table, with rows and named columns\n",
        "*   **Series**: a single column\n",
        "\n",
        "A DataFrame contains one or more Series and a name for each Series.\n",
        "For now, we'll focus on working with dataframes, and start by loading an entire file into a DataFrame.\n",
        "\n",
        "Run the following cell to load the data and create feature definitions:"
      ],
      "metadata": {
        "id": "bH1uJJ7Fpinz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# csv file is a file with \"comma separated values\", it's implied with .read_csv() that sep=','\n",
        "california_housing_dataframe = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\", sep=\",\")\n",
        "california_housing_dataframe.head() # .head() allows you to visualize the first 5 rows (the \"head\" of the dataset)\n",
        "\n",
        "# how would you visualize the last 5 rows?"
      ],
      "metadata": {
        "id": "ntlwUS0vpmpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The example above used `DataFrame.head`, which displays the first few records of a `DataFrame`. Another useful function to analyze data is `DataFrame.hist`, which displays the distribution of values in a column visualized as a graph."
      ],
      "metadata": {
        "id": "gZOOrkMQqx0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# display distribution of values in the 'housing_median_age column\n",
        "california_housing_dataframe.hist('housing_median_age')"
      ],
      "metadata": {
        "id": "u2EVIyt1qRso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `.shape` function returns a tuple representing the dimenionality of the dataset."
      ],
      "metadata": {
        "id": "0iK_meW3-ZKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: print the number of rows and columns in the dataset\n",
        "num_rows = california_housing_dataframe.shape[0]\n",
        "num_cols = # TODO---------------\n",
        "\n",
        "print(\"The dataset has %d rows\" %num_rows)\n",
        "print(\"The dataset has %d columns\" %num_cols)"
      ],
      "metadata": {
        "id": "hPS6V6B29603"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Indexing and Filtering**\n",
        "We can select a column by calling `df['column_name']`, and select a specific row by index when using `df.iloc[i]` for some integer i. For simplicity, let's work with a much smaller subset of our housing dataset for better visualization."
      ],
      "metadata": {
        "id": "WQD7J3hZ-drP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the default number of rows displayed by head is 5, but we can enter in a custom parameter for the number of rows we want\n",
        "df = california_housing_dataframe.head(10)\n",
        "\n",
        "#TODO: determine the max amount of total bedrooms in df\n",
        "max_total_bedrooms = #TODO--------\n",
        "max_total_bedrooms"
      ],
      "metadata": {
        "id": "UbpsKWtG-hME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is also useful to filter the dataset based on certain criteria. For example, `df[df.population > 500]` display only the entries where `population > 500`."
      ],
      "metadata": {
        "id": "AAEjvh1H-r_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: display entries where households > 250 and population > 700\n",
        "df_1 = #TODO--------------\n",
        "df_1"
      ],
      "metadata": {
        "id": "FkQ3kYk7-tAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Manipulating Data**\n",
        "Let's try adding a column of categorical variables, also known as *dummy variables*, which represents which county each row belongs in to our dataset. Since raw county names may be very long strings, it's easier to use them in analysis when converted into a series of dummy or indicator variables. Below are our different categories.\n",
        "*    \"Orange County\"\n",
        "*    \"Los Angeles\"\n",
        "*    \"Santa Clara\"\n",
        "\n",
        "We can use `pd.get_dummies` to make this conversion."
      ],
      "metadata": {
        "id": "vGO26LiD-v9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "county = [ \"OC\", \"LA\", \"LA\", \"SC\", \"LA\", \"OC\", \"OC\", \"LA\", \"SC\", \"SC\"]\n",
        "# create a pandas series\n",
        "series = pd.Series(county)\n",
        "\n",
        "# TODO: convert to dummy variables\n",
        "dummies = #TODO----------------\n",
        "dummies"
      ],
      "metadata": {
        "id": "qcVbxniV-4ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: add our dummy variables to df as new columns\n",
        "new_df = #TODO-------------------\n",
        "new_df"
      ],
      "metadata": {
        "id": "_rhkXU1aBqVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Numpy**\n",
        "\n",
        "Numpy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays.\n",
        "\n",
        "To use Numpy, we first need to import the `numpy` package as done below:"
      ],
      "metadata": {
        "id": "FY3oE2HSzMIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "k0uwSwT7zUem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Arrays\n",
        "A numpy array is a grid of values, all of the same type, and is indexed by a tuple of nonnegative integers. The number of dimensions is the rank of the array; the shape of an array is a tuple of integers giving the size of the array along each dimension.\n",
        "We can initialize numpy arrays from nested Python lists, and access elements using square brackets:"
      ],
      "metadata": {
        "id": "BazUjUk90ng3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a rank 1 array\n",
        "a = np.array([1, 2, 3])\n",
        "print(type(a), a.shape, a[0], a[1], a[2])\n",
        "\n",
        "# change value of the array[0] to be 5\n",
        "a[0] = 5\n",
        "print(a)"
      ],
      "metadata": {
        "id": "_XwAcuuu036D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Array indexing**\n",
        "\n",
        "Numpy offers several ways to index into arrays. Similar to Python lists, numpy arrays can also be sliced. Since arrays may be multidimensional, you must specify a slice for each dimension of the array."
      ],
      "metadata": {
        "id": "RVSwZ4ef1a8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# TODO: Create the following rank 2 array (2 dimensions) with shape (3, 4) using .arange() and .reshape()\n",
        "# [[ 1  2  3  4]\n",
        "#  [ 5  6  7  8]\n",
        "#  [ 9 10 11 12]]\n",
        "a = # TODO--------------------\n",
        "\n",
        "# TODO: Use slicing to pull out the subarray consisting of the first 2 rows and middle two columns\n",
        "# [[2 3]\n",
        "#  [6 7]]\n",
        "b = # TODO-----------------------\n",
        "print(b)"
      ],
      "metadata": {
        "id": "5w0EVU_f1oNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTctwqdQL9ih"
      },
      "source": [
        "###**Datatypes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSZQ1WkIL9ih"
      },
      "source": [
        "Every numpy array is a grid of elements of the same type. Numpy provides a large set of numeric datatypes that you can use to construct arrays. Numpy tries to guess a datatype when you create an array, but functions that construct arrays usually also include an optional argument to explicitly specify the datatype. Here is an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4za4O0m5L9ih"
      },
      "outputs": [],
      "source": [
        "x = np.array([1, 2])  # Let numpy choose the datatype\n",
        "y = np.array([1.0, 2.0])  # Let numpy choose the datatype\n",
        "z = np.array([1, 2], dtype=np.int64)  # Force a particular datatype\n",
        "\n",
        "print(x.dtype, y.dtype, z.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLVIsZQpL9ik"
      },
      "source": [
        "You can read all about numpy datatypes in the [documentation](http://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Array Math**"
      ],
      "metadata": {
        "id": "Ksv_Yue72Zpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic mathematical functions operate elementwise on arrays, and are available both as operator overloads and as functions in the numpy module:"
      ],
      "metadata": {
        "id": "oJP8_hHb2cKK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHKvBrSKL9il"
      },
      "outputs": [],
      "source": [
        "x = np.array([[1,2],[3,4]], dtype=np.float64)\n",
        "y = np.array([[5,6],[7,8]], dtype=np.float64)\n",
        "\n",
        "print(x)\n",
        "print(y, '\\n')\n",
        "# TODO: print the elementwise product\n",
        "print('TODO'')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The multiplication above is strictly element-wise, not a dot product of the matrices. To get the dot product, use `np.dot`."
      ],
      "metadata": {
        "id": "VNJmHhDF3QCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = np.array([9, 10])\n",
        "w = np.array([11, 12])\n",
        "\n",
        "# TODO: print the dot product of v and w (219)\n",
        "print('TODO')"
      ],
      "metadata": {
        "id": "xAenl3674HW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Broadcasting**\n",
        "The term broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, the smaller array is “broadcast” across the larger array so that they have compatible shapes."
      ],
      "metadata": {
        "id": "yaJpaV4dES-_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0iZuA6bL9ir"
      },
      "outputs": [],
      "source": [
        "# broadcasting example\n",
        "a = np.array([0, 3, 6])\n",
        "b = 5\n",
        "print(a + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nil4AScML9io"
      },
      "outputs": [],
      "source": [
        "# TODO: create a 3x3 np array of all ones\n",
        "M = # TODO--------------------\n",
        "# what happens if you add M to a?\n",
        "print(M + a)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Pytorch**\n",
        "\n",
        "Now let's get into Pytorch! We choose to use PyTorch at CAIS++ because it is well established in research, has a huge developer community (originally developed by Facebook), and takes advantage of high-speed GPU performance (especially with the Collab GPUs!). Alternatives to PyTorch include [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax#quickstart-colab-in-the-cloud) and [Caffe](http://caffe.berkeleyvision.org/)."
      ],
      "metadata": {
        "id": "jpgzzdrij77y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "rRn72plzjWx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For every machine learning framework, a very good practice is to setup your code to be reproducible with the exact same random numbers. We do this by setting a seed."
      ],
      "metadata": {
        "id": "qR8H1I58mdio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42) # Setting the seed"
      ],
      "metadata": {
        "id": "as5z9EfPmcyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Tensors**\n",
        "\n",
        "Tensors are the PyTorch equivalent to Numpy arrays, with the addition to also have support for GPU acceleration. The name \"tensor\" is a generalization of concepts you already know. For instance, a vector is a 1-D tensor, and a matrix a 2-D tensor. When working with neural networks, we will use tensors of various shapes and number of dimensions.\n",
        "\n",
        "**Initialization**\n",
        "\n",
        "Let's first start by looking at different ways of creating a tensor. There are many possible options, the most simple one is to call `torch.Tensor` passing the desired shape as input argument:"
      ],
      "metadata": {
        "id": "wkGUoQuNm8EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(2, 3, 4) # create a tensor with shape [2, 3, 4]\n",
        "print(x)"
      ],
      "metadata": {
        "id": "-OnMe4I3nlg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `torch.Tensor` allocates memory for the desired tensor, but reuses any values that have already been in the memory. To directly assign values to the tensor during initialization, there are many alternatives including:\n",
        "\n",
        "* `torch.zeros`: Creates a tensor filled with zeros\n",
        "* `torch.ones`: Creates a tensor filled with ones\n",
        "* `torch.rand`: Creates a tensor with random values uniformly sampled between 0 and 1\n",
        "* `torch.randn`: Creates a tensor with random values sampled from a normal distribution with mean 0 and variance 1\n",
        "* `torch.arange`: Creates a tensor containing the values $N,N+1,N+2,...,M$\n",
        "* `torch.Tensor` (input list): Creates a tensor from the list elements you provide"
      ],
      "metadata": {
        "id": "cStWRkFjn9Mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with random values between 0 and 1 with the shape [2, 3, 4]\n",
        "x = torch.rand(2, 3, 4)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "yYJhUwxGoInP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO create an Integer tensor from list [[1, 2], [3, 4]]\n",
        "x_data = # TODO-----------------------\n",
        "print(x_data)"
      ],
      "metadata": {
        "id": "xmcb20L7oGGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
      ],
      "metadata": {
        "id": "QNsfVOT8qF3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "id": "t-bxxJ62qHfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can obtain the shape, datatype, and the device on which they are stored:"
      ],
      "metadata": {
        "id": "wA18EatDoOA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: print the shape x_data\n",
        "print(f\"Shape of tensor: {'TODO'}\")\n",
        "\n",
        "# TODO: print the datatype of x_data\n",
        "print(f\"Datatype of tensor: {'TODO'}\")\n",
        "\n",
        "# TODO: print the device x_data is stored on\n",
        "print(f\"Device tensor is stored on: {'TODO'}\")"
      ],
      "metadata": {
        "id": "4DwI7AwGoTjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor to Numpy, and Numpy to Tensor**\n",
        "\n",
        "Tensors can be converted to numpy arrays, and numpy arrays back to tensors. To transform a numpy array into a tensor, we can use the function `torch.from_numpy`:"
      ],
      "metadata": {
        "id": "1-X5CIKxjkEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_arr = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# TODO: create tensor from numpy array\n",
        "tensor = # TODO----------------------\n",
        "\n",
        "print(\"Numpy array:\", np_arr)\n",
        "print(\"PyTorch tensor:\", tensor)"
      ],
      "metadata": {
        "id": "KWPScn0nouY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To transform a PyTorch tensor back to a numpy array, we can use the function `.numpy()` on tensors:"
      ],
      "metadata": {
        "id": "-V-PBbhZo01l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.arange(4)\n",
        "\n",
        "# TODO: create numpy array from tensor\n",
        "np_arr = # TODO---------------------\n",
        "\n",
        "print(\"PyTorch tensor:\", tensor)\n",
        "print(\"Numpy array:\", np_arr)"
      ],
      "metadata": {
        "id": "X5VxebvCo2kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Operations**\n",
        "\n",
        "Most operations that exist in numpy, also exist in PyTorch. A full list of operations can be found in the [PyTorch documentation](https://pytorch.org/docs/stable/tensors.html#), but we will review the most important ones here."
      ],
      "metadata": {
        "id": "MyoRaKM5sf47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "y = x1 + x2\n",
        "\n",
        "print(\"X1\", x1)\n",
        "print(\"X2\", x2)\n",
        "print(\"Y\", y)"
      ],
      "metadata": {
        "id": "cu5IBO1-seXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling `x1 + x2` creates a new tensor containing the sum of the two inputs. However, we can also use in-place operations that are applied directly on the memory of a tensor with the `.add_` function (`x2 += x1`)."
      ],
      "metadata": {
        "id": "zqIzjL_2s78_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(2, 3)\n",
        "print(\"X1 (before)\", x1)\n",
        "print(\"X2 (before)\", x2)\n",
        "\n",
        "# TODO: implement x2 += x1\n",
        "\n",
        "print(\"X1 (after)\", x1)\n",
        "print(\"X2 (after)\", x2)"
      ],
      "metadata": {
        "id": "5TrJHcT2tCvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other commonly used operations include matrix multiplications, which are essential for neural networks. Quite often, we have an input vector $\\mathbf{x}$, which is transformed using a learned weight matrix $\\mathbf{W}$. There are multiple ways and functions to perform matrix multiplication, some of which we list below:\n",
        "\n",
        "* `torch.matmul`: Performs the matrix product over two tensors, where the specific behavior depends on the dimensions. If both inputs are matrices (2-dimensional tensors), it performs the standard matrix product. For higher dimensional inputs, the function supports broadcasting (for details see the [documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=matmul#torch.matmul)). Can also be written as `a @ b`, similar to numpy.\n",
        "* `torch.mm`: Performs the matrix product over two matrices, but doesn't support broadcasting (see [documentation](https://pytorch.org/docs/stable/generated/torch.mm.html?highlight=torch%20mm#torch.mm))\n",
        "* `torch.bmm`: Performs the matrix product with a support batch dimension. If the first tensor $T$ is of shape ($b\\times n\\times m$), and the second tensor $R$ ($b\\times m\\times p$), the output $O$ is of shape ($b\\times n\\times p$), and has been calculated by performing $b$ matrix multiplications of the submatrices of $T$ and $R$: $O_i = T_i @ R_i$\n",
        "* `torch.einsum`: Performs matrix multiplications and more (i.e. sums of products) using the Einstein summation convention. Explanation of the Einstein sum can be found in assignment 1.\n",
        "\n",
        "Usually, we use `torch.matmul` or `torch.bmm`. We can try a matrix multiplication with `torch.matmul` below."
      ],
      "metadata": {
        "id": "v2_q6cRPtOGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(6)\n",
        "x = x.view(2, 3)\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "86D4E_eftRSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.arange(9).view(3, 3) # We can also stack multiple operations in a single line\n",
        "print(\"W\", W)"
      ],
      "metadata": {
        "id": "xAFPNW5ftvuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO find the matrix product of x and W\n",
        "h = # TODO-----------------------\n",
        "\n",
        "# Verify the result by calculating it by hand too!\n",
        "print(\"h\", h)"
      ],
      "metadata": {
        "id": "Twg7uBqUt2nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Indexing**\n",
        "\n",
        "We often have the situation where we need to select a part of a tensor. Indexing works just like in numpy, so let's try it:"
      ],
      "metadata": {
        "id": "A1o-PTuquush"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(12).view(3, 4)\n",
        "print(\"X\", x)\n",
        "print(x[:, 1])   # Second column\n",
        "print(x[0])      # First row\n",
        "print(x[:2, -1]) # First two rows, last column\n",
        "\n",
        "# TODO: print the last two rows of x\n"
      ],
      "metadata": {
        "id": "L1yAGwJnuzLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GPU support**\n",
        "\n",
        "A crucial feature of PyTorch is the support of GPUs, short for Graphics Processing Unit. GPUs can accelerate the training of your network up to a factor of $100$ which is essential for our future models. PyTorch implements a lot of functionality for supporting GPUs (mostly those of NVIDIA due to the libraries [CUDA](https://developer.nvidia.com/cuda-zone) and [cuDNN](https://developer.nvidia.com/cudnn)). First, let's check whether you have a GPU available (you should, since you should be connected already):"
      ],
      "metadata": {
        "id": "urhnoeSmvhzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_avail = torch.cuda.is_available()\n",
        "print(f\"Is the GPU available? {gpu_avail}\")"
      ],
      "metadata": {
        "id": "49yU6xXFvxr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, all tensors you create are stored on the CPU. We can push a tensor to the GPU by using the function `.to(...)`, or `.cuda()`. However, it is often a good practice to define a `device` object in your code which points to the GPU if you have one, and otherwise to the CPU. We can specify the device as follows:"
      ],
      "metadata": {
        "id": "3kOK3c2YwKwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)"
      ],
      "metadata": {
        "id": "DlBgdrNDwTJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's create a tensor and push it to the device:"
      ],
      "metadata": {
        "id": "4JIsioP8waDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 3)\n",
        "# TODO: push x to device\n",
        "x = # TODO---------------------\n",
        "print(\"X\", x)"
      ],
      "metadata": {
        "id": "TJSDGjL5wavZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also compare the runtime of a large matrix multiplication on the CPU with a operation on the GPU:"
      ],
      "metadata": {
        "id": "DSwV2iMMwlco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "x = torch.randn(5000, 5000)\n",
        "\n",
        "## CPU version\n",
        "start_time = time.time()\n",
        "_ = torch.matmul(x, x)\n",
        "end_time = time.time()\n",
        "print(f\"CPU time: {(end_time - start_time):6.5f}s\")\n",
        "\n",
        "## GPU version\n",
        "x = x.to(device)\n",
        "# CUDA is asynchronous, so we need to use different timing functions\n",
        "start = torch.cuda.Event(enable_timing=True)\n",
        "end = torch.cuda.Event(enable_timing=True)\n",
        "start.record()\n",
        "_ = torch.matmul(x, x)\n",
        "end.record()\n",
        "torch.cuda.synchronize()  # Waits for everything to finish running on the GPU\n",
        "print(f\"GPU time: {0.001 * start.elapsed_time(end):6.5f}s\")  # Milliseconds to seconds"
      ],
      "metadata": {
        "id": "jkRy61mowk8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When generating random numbers, the seed between CPU and GPU is not synchronized, so we must also set the seed on the GPU:"
      ],
      "metadata": {
        "id": "YcA3x-Oaw0n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU operations have a separate seed we also want to set\n",
        "if torch.cuda.is_available():\n",
        "    # TODO: set seed on GPU\n",
        "\n",
        "\n",
        "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "W8_6w262xFqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Congrats! You just finished your first notebook!"
      ],
      "metadata": {
        "id": "tRjskb8XhjAQ"
      }
    }
  ]
}